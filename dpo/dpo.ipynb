{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "124a869a",
   "metadata": {},
   "source": [
    "### Step 1: Install necesscary packages"
   ]
  },
  {
   "cell_type": "code",
   "id": "3b82f8f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T12:06:53.848551Z",
     "start_time": "2025-10-10T12:06:52.402190Z"
    }
   },
   "source": [
    "!pip install matplotlib\n",
    "!pip install torch numpy transformers datasets tiktoken wandb tqdm"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /opt/homebrew/lib/python3.11/site-packages (3.8.3)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib) (1.2.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib) (4.49.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib) (1.4.5)\r\n",
      "Requirement already satisfied: numpy<2,>=1.21 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib) (1.24.3)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib) (23.2)\r\n",
      "Requirement already satisfied: pillow>=8 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib) (10.2.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib) (3.1.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib) (2.8.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m25.1.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49m/opt/homebrew/opt/python@3.11/bin/python3.11 -m pip install --upgrade pip\u001B[0m\r\n",
      "Requirement already satisfied: torch in /opt/homebrew/lib/python3.11/site-packages (2.8.0)\r\n",
      "Requirement already satisfied: numpy in /opt/homebrew/lib/python3.11/site-packages (1.24.3)\r\n",
      "Requirement already satisfied: transformers in /opt/homebrew/lib/python3.11/site-packages (4.57.0)\r\n",
      "Requirement already satisfied: datasets in /opt/homebrew/lib/python3.11/site-packages (4.1.1)\r\n",
      "Requirement already satisfied: tiktoken in /opt/homebrew/lib/python3.11/site-packages (0.12.0)\r\n",
      "Requirement already satisfied: wandb in /opt/homebrew/lib/python3.11/site-packages (0.22.2)\r\n",
      "Requirement already satisfied: tqdm in /opt/homebrew/lib/python3.11/site-packages (4.67.1)\r\n",
      "Requirement already satisfied: filelock in /opt/homebrew/lib/python3.11/site-packages (from torch) (3.20.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/homebrew/lib/python3.11/site-packages (from torch) (4.15.0)\r\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/homebrew/lib/python3.11/site-packages (from torch) (1.14.0)\r\n",
      "Requirement already satisfied: networkx in /opt/homebrew/lib/python3.11/site-packages (from torch) (3.5)\r\n",
      "Requirement already satisfied: jinja2 in /opt/homebrew/lib/python3.11/site-packages (from torch) (3.1.2)\r\n",
      "Requirement already satisfied: fsspec in /opt/homebrew/lib/python3.11/site-packages (from torch) (2025.9.0)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /opt/homebrew/lib/python3.11/site-packages (from transformers) (0.35.3)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/homebrew/lib/python3.11/site-packages (from transformers) (23.2)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/homebrew/lib/python3.11/site-packages (from transformers) (6.0.1)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/homebrew/lib/python3.11/site-packages (from transformers) (2025.9.18)\r\n",
      "Requirement already satisfied: requests in /opt/homebrew/lib/python3.11/site-packages (from transformers) (2.32.3)\r\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /opt/homebrew/lib/python3.11/site-packages (from transformers) (0.22.1)\r\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/homebrew/lib/python3.11/site-packages (from transformers) (0.6.2)\r\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/homebrew/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\r\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /opt/homebrew/lib/python3.11/site-packages (from datasets) (21.0.0)\r\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /opt/homebrew/lib/python3.11/site-packages (from datasets) (0.4.0)\r\n",
      "Requirement already satisfied: pandas in /opt/homebrew/lib/python3.11/site-packages (from datasets) (2.2.1)\r\n",
      "Requirement already satisfied: xxhash in /opt/homebrew/lib/python3.11/site-packages (from datasets) (3.6.0)\r\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/homebrew/lib/python3.11/site-packages (from datasets) (0.70.16)\r\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/homebrew/lib/python3.11/site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (3.8.5)\r\n",
      "Requirement already satisfied: click>=8.0.1 in /opt/homebrew/lib/python3.11/site-packages (from wandb) (8.1.6)\r\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/homebrew/lib/python3.11/site-packages (from wandb) (3.1.45)\r\n",
      "Requirement already satisfied: platformdirs in /Users/juliusmaxwahler/Library/Python/3.11/lib/python/site-packages (from wandb) (4.3.8)\r\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /opt/homebrew/lib/python3.11/site-packages (from wandb) (6.32.1)\r\n",
      "Requirement already satisfied: pydantic<3 in /opt/homebrew/lib/python3.11/site-packages (from wandb) (2.5.0)\r\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /opt/homebrew/lib/python3.11/site-packages (from wandb) (2.40.0)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/homebrew/lib/python3.11/site-packages (from pydantic<3->wandb) (0.5.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.14.1 in /opt/homebrew/lib/python3.11/site-packages (from pydantic<3->wandb) (2.14.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/lib/python3.11/site-packages (from requests->transformers) (3.2.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/lib/python3.11/site-packages (from requests->transformers) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/lib/python3.11/site-packages (from requests->transformers) (2.4.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/lib/python3.11/site-packages (from requests->transformers) (2023.7.22)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (23.1.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (6.0.4)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (4.0.2)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.9.2)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.4.0)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.3.1)\r\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/homebrew/lib/python3.11/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\r\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/homebrew/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/homebrew/lib/python3.11/site-packages (from sympy>=1.13.3->torch) (1.3.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/lib/python3.11/site-packages (from jinja2->torch) (2.1.3)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/homebrew/lib/python3.11/site-packages (from pandas->datasets) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/lib/python3.11/site-packages (from pandas->datasets) (2024.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/homebrew/lib/python3.11/site-packages (from pandas->datasets) (2024.1)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m25.1.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49m/opt/homebrew/opt/python@3.11/bin/python3.11 -m pip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "6c2d9de0",
   "metadata": {},
   "source": [
    "### Step 2: Package imports and configuration"
   ]
  },
  {
   "cell_type": "code",
   "id": "876dd92d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T12:07:57.443302Z",
     "start_time": "2025-10-10T12:07:55.144014Z"
    }
   },
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"..\")) \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import pickle\n",
    "from model import GPT, GPTConfig\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "# Configuration\n",
    "beta = 0.5\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "base_lr = 1e-4\n",
    "epochs = 5\n",
    "batch_size = 64\n",
    "max_length =64\n",
    "num_samples = 1\n",
    "max_new_tokens = 200\n",
    "temperature = 0.8\n",
    "top_k = 200\n",
    "# tokenizer\n",
    "with open(\"../sft/meta.pkl\", \"rb\") as f:\n",
    "    meta = pickle.load(f)\n",
    "stoi, itos = meta[\"stoi\"], meta[\"itos\"]\n",
    "def encode(s): return [stoi[c] for c in s]\n",
    "def decode(l): return ''.join([itos[i] for i in l])"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "4c7d35e6",
   "metadata": {},
   "source": [
    "### Step 3: Define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "id": "d03655c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T12:08:14.793252Z",
     "start_time": "2025-10-10T12:08:14.786999Z"
    }
   },
   "source": [
    "def compute_logprob(input_ids):\n",
    "    inputs = input_ids[:, :-1]\n",
    "    targets = input_ids[:, 1:]\n",
    "    logits, _ = gpt(inputs, full_seq=True)\n",
    "    B, T, V = logits.size()\n",
    "    logits_flat = logits.reshape(-1, V)\n",
    "    targets_flat = targets.reshape(-1)\n",
    "    loss = F.cross_entropy(logits_flat, targets_flat, ignore_index=0, reduction='none')\n",
    "    loss = loss.reshape(B, T)\n",
    "    attention_mask = (targets != 0).float()\n",
    "    loss = (loss * attention_mask).sum(dim=1) / attention_mask.sum(dim=1)\n",
    "    return -loss \n",
    "\n",
    "def pad_or_truncate(seq, max_length):\n",
    "    return seq[-max_length:] if len(seq) > max_length else seq + [0] * (max_length - len(seq))\n",
    "\n",
    "def get_batches(lines, batch_size):\n",
    "    random.shuffle(lines)\n",
    "    #for l in lines:\n",
    "    #    print(l[1])\n",
    "    for i in range(0, len(lines), batch_size):\n",
    "        batch = lines[i:i+batch_size]\n",
    "        if len(batch) < batch_size:\n",
    "            continue\n",
    "        neg_inputs = [pad_or_truncate(encode(p['negative'] + '\\n\\n\\n\\n'), max_length) for p in batch]\n",
    "        pos_inputs = [pad_or_truncate(encode(p['positive'] + '\\n\\n\\n\\n'), max_length) for p in batch]\n",
    "        neg_tensor = torch.tensor(neg_inputs, dtype=torch.long, device=device)\n",
    "        pos_tensor = torch.tensor(pos_inputs, dtype=torch.long, device=device)\n",
    "        yield neg_tensor, pos_tensor"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "fc9d9eba",
   "metadata": {},
   "source": [
    "### Step 4: Load the pretrained NanoGPT model"
   ]
  },
  {
   "cell_type": "code",
   "id": "ceae772a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T12:10:52.611079Z",
     "start_time": "2025-10-10T12:10:52.355415Z"
    }
   },
   "source": [
    "ckpt = torch.load(\"../sft/gpt.pt\", map_location=device)\n",
    "gptconf = GPTConfig(**ckpt['model_args'])\n",
    "gpt = GPT(gptconf)\n",
    "state_dict = ckpt['model']\n",
    "unwanted_prefix = '_orig_mod.'\n",
    "for k in list(state_dict.keys()):\n",
    "    if k.startswith(unwanted_prefix):\n",
    "        state_dict[k[len(unwanted_prefix):]] = state_dict.pop(k)\n",
    "gpt.load_state_dict(state_dict)\n",
    "gpt.to(device).train()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT(\n",
       "  (transformer): ModuleDict(\n",
       "    (wte): Embedding(74, 348)\n",
       "    (wpe): Embedding(256, 348)\n",
       "    (drop): Dropout(p=0.2, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-5): 6 x Block(\n",
       "        (ln_1): LayerNorm()\n",
       "        (attn): CausalSelfAttention(\n",
       "          (c_attn): Linear(in_features=348, out_features=1044, bias=False)\n",
       "          (c_proj): Linear(in_features=348, out_features=348, bias=False)\n",
       "          (attn_dropout): Dropout(p=0.2, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm()\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Linear(in_features=348, out_features=1392, bias=False)\n",
       "          (gelu): GELU(approximate='none')\n",
       "          (c_proj): Linear(in_features=1392, out_features=348, bias=False)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=348, out_features=74, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "0feafc5a",
   "metadata": {},
   "source": [
    "### Step 5: Load Data (**students are required to complete this part!**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7edf3d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, random\n",
    "\n",
    "def build_dataset(n=100000, out_path=\"./data/pos_neg_pairs.json\"):\n",
    "    pairs = []\n",
    "    for _ in range(n):\n",
    "        a, b = random.randint(1,100), random.randint(1,100)\n",
    "        op = random.choice([\"+\", \"-\", \"*\"])\n",
    "        if op == \"+\":\n",
    "            ans = a+b; reason = f\"{a}+{b} equals {ans}\"\n",
    "        elif op == \"-\":\n",
    "            ans = a-b; reason = f\"{a}-{b} equals {ans}\"\n",
    "        else:\n",
    "            ans = a*b; reason = f\"{a}*{b} equals {ans}\"\n",
    "        q = f\"{a}{op}{b}, x=?\"\n",
    "        pos = f\"{q} The answer is {ans} because {reason}.\"\n",
    "        neg = f\"{q} Sorry, I do not know!\"\n",
    "        pairs.append({\"negative\": neg, \"positive\": pos})\n",
    "\n",
    "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(pairs, f, indent=2)\n",
    "    print(f\"Saved {len(pairs)} pairs to {out_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e5f81f",
   "metadata": {},
   "source": [
    "### Step 6: Build the optimizer and scheduler (**students are required to complete this part!**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df0c400f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "#optimizer (AdamW)\n",
    "optimizer = AdamW(gpt.parameters(), lr=1e-5, weight_decay=0.01)\n",
    "\n",
    "#scheduler\n",
    "num_training_steps = 1000  # for example\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=100,\n",
    "    num_training_steps=num_training_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b66199",
   "metadata": {},
   "source": [
    "### Step 7: Begin training (**students are required to complete this part!**)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "ca312a9bc03ea15a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4ebeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_steps = len(lines) // batch_size\n",
    "for epoch in range(epochs):\n",
    "    pbar = tqdm(get_batches(lines, batch_size))\n",
    "    for step, (neg_tensor,pos_tensor) in enumerate(pbar):\n",
    "        ###########################################################\n",
    "        # Please complete the training code here!\n",
    "        # Examples: \n",
    "        # ...\n",
    "        # neg_logprob\n",
    "        # pos_logprob \n",
    "        # loss = -F.logsigmoid((pos_logprob - neg_logprob) / beta).mean() - pos_logprob.mean() * 0.1 \n",
    "        # ...\n",
    "        ###########################################################\n",
    "    ckpt_path = f\"./dpo.pt\"\n",
    "    torch.save({\n",
    "        \"model_state_dict\": gpt.state_dict(),\n",
    "        \"model_args\": ckpt['model_args'],\n",
    "    }, ckpt_path)\n",
    "    print(f\"Saved checkpoint to {ckpt_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b7f2ab",
   "metadata": {},
   "source": [
    "### Step 8: Begin testing (**students are required to complete this part!**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09027262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the fine-tuned model\n",
    "ckpt_path = \"../dpo/dpo.pt\"\n",
    "checkpoint = torch.load(ckpt_path, map_location=device)\n",
    "gptconf = GPTConfig(**checkpoint['model_args'])\n",
    "gpt = GPT(gptconf).cuda()\n",
    "try:\n",
    "    state_dict = checkpoint['model']\n",
    "except:\n",
    "    state_dict = checkpoint['model_state_dict']\n",
    "unwanted_prefix = '_orig_mod.'\n",
    "for k,v in list(state_dict.items()):\n",
    "    if k.startswith(unwanted_prefix):\n",
    "        state_dict[k[len(unwanted_prefix):]] = state_dict.pop(k)\n",
    "gpt.load_state_dict(state_dict)\n",
    "# Test\n",
    "gpt.eval()\n",
    "test_set = [\"17+19=?\", \"3*17=?\", \"72/4=?\", \"72-x=34,x=?\", \"x*11=44,x=?\", \"3*17=?\", \"72/4=?\", \"72-x=34,x=?\"]\n",
    "with torch.no_grad():\n",
    "    for prompt in test_set: \n",
    "        prompt_ids = encode(prompt)\n",
    "        ###########################################################\n",
    "        # Please complete the test code here!\n",
    "        # ...\n",
    "        # gpt.generate(x, max_new_tokens, temperature=temperature, top_k=top_k)\n",
    "        # ...\n",
    "        ###########################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nanogpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
